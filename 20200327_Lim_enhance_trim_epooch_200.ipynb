{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldtHMhuLrewK"
   },
   "source": [
    "**Model 1**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting librosa\n",
      "Collecting audioread>=2.0.0 (from librosa)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from librosa) (0.19.2)\n",
      "Collecting joblib>=0.12 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: decorator>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa) (4.3.0)\n",
      "Requirement already satisfied: six>=1.3 in /opt/conda/lib/python3.6/site-packages (from librosa) (1.11.0)\n",
      "Collecting soundfile>=0.9.0 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from librosa) (1.1.0)\n",
      "Collecting resampy>=0.2.2 (from librosa)\n",
      "Collecting numba>=0.43.0 (from librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/ba/49/61522f34b1333aa4e9aa02005dc0774d25bd234400dff718b16615d6a744/numba-0.48.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.6/site-packages (from librosa) (1.15.4)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.6/site-packages (from soundfile>=0.9.0->librosa) (1.11.5)\n",
      "Collecting llvmlite<0.32.0,>=0.31.0dev0 (from numba>=0.43.0->librosa)\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/bb/60d4033d56c9da36490af19caa6c794b72b8aef6f792fdfa8cb95d11e419/llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from numba>=0.43.0->librosa) (40.2.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0->soundfile>=0.9.0->librosa) (2.18)\n",
      "Installing collected packages: audioread, joblib, soundfile, llvmlite, numba, resampy, librosa\n",
      "  Found existing installation: llvmlite 0.23.0\n",
      "    Uninstalling llvmlite-0.23.0:\n",
      "      Successfully uninstalled llvmlite-0.23.0\n",
      "  Found existing installation: numba 0.38.1\n",
      "    Uninstalling numba-0.38.1:\n",
      "      Successfully uninstalled numba-0.38.1\n",
      "Successfully installed audioread-2.1.8 joblib-0.14.1 librosa-0.7.2 llvmlite-0.31.0 numba-0.48.0 resampy-0.2.2 soundfile-0.10.3.post1\n"
     ]
    }
   ],
   "source": [
    "#librosa 只有第一次需要裝\n",
    "\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "import tensorflow\n",
    "\n",
    "# Reset Keras Session\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tensorflow.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tensorflow.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "#載入所有需要的套件\n",
    "\n",
    "import librosa\n",
    "from librosa import display\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras\n",
    "#import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Input, Flatten, Dropout, Activation\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCtNuVWlr5jL"
   },
   "source": [
    "# 進行建模事前準備\n",
    "## 設定檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '../../dataset/ravdess_datasets/Audio_Song_Actors/Actor_01'\n",
    "path = '/home/jovyan/at083-group21/dataset/ravdess_datasets/'\n",
    "\n",
    "lst = []\n",
    "#save_dir = 'joblib'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim db 30\n",
    "def trim(data):\n",
    "    data, index = librosa.effects.trim(data, top_db=30, frame_length=1024, hop_length=512) # default frame_length=2048, hop_length=512\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCtNuVWlr5jL"
   },
   "source": [
    "##  讀資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start load Data. Start time: 1585707887.4737136 ---\n"
     ]
    }
   ],
   "source": [
    "#trim\n",
    "## Trim\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"--- Start load Data. Start time: %s ---\" % (start_time))\n",
    "for subdir, dirs, files in os.walk(path):\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
    "            X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
    "            \n",
    "            #####Data Augmentation\n",
    "                        \n",
    "            X = trim(X)\n",
    "            sample_rate = np.array(sample_rate)\n",
    "\n",
    "            \n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=100).T,axis=0) \n",
    "            # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
    "            # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
    "            file = int(file[7:8]) - 1 \n",
    "            arr = mfccs, file\n",
    "            lst.append(arr)\n",
    "          # If the file is not valid, skip it\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
    "X, y = zip(*lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2244, 100), (2244,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1503, 100, 1), (741, 100, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn.shape, x_testcnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saving joblib files to not load them again with the loop above\n",
    "X_name = 'Adam_trim_only_aug_X.joblib'\n",
    "y_name = 'Adam_trim_only_aug_y.joblib'\n",
    "save_dir = '/home/jovyan/project_model_training/final_test_folder/20200327/'\n",
    "#save_dir = 'joblib'\n",
    "savedX = joblib.dump(X, os.path.join(save_dir, X_name))\n",
    "savedy = joblib.dump(y, os.path.join(save_dir, y_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1503, 100, 1), (741, 100, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading saved models\n",
    "\n",
    "#save_dir = '/home/jovyan/project_model_training/final_test_folder/20200326_Adam_data_augmentation/'\n",
    "save_dir = '/home/jovyan/project_model_training/final_test_folder/20200327/'\n",
    "\n",
    "X = joblib.load(f'{save_dir}/Adam_trim_only_aug_X.joblib')\n",
    "y = joblib.load(f'{save_dir}/Adam_trim_only_aug_y.joblib')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "x_traincnn = np.expand_dims(X_train, axis=2)\n",
    "x_testcnn = np.expand_dims(X_test, axis=2)\n",
    "\n",
    "x_traincnn.shape, x_testcnn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCVgjLj-gwE2"
   },
   "source": [
    "### 模型3: Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU, PReLU, LeakyReLU\n",
    "import tensorflow as tf\n",
    "\n",
    "opt = keras.optimizers.Adam(lr=0.00001, decay=1e-6)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(128, 5, padding='same', input_shape=(None,1)))\n",
    "model.add(BatchNormalization())   # Instance Normalization. Because of batch size=1.\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.06))\n",
    "\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.06))\n",
    "\n",
    "model.add(Conv1D(128, 5,padding='same',))\n",
    "model.add(BatchNormalization())\n",
    "x=model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.06))\n",
    "\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(8))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "          optimizer=opt,\n",
    "          metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 497,672\n",
      "Trainable params: 495,880\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkpoint\n",
    "#from keras.callbacks import ModelCheckpoint\n",
    "#filepath=\"./model_1_1_NoDA_48_nmfcc13_lr5e-05_{epoch:02d}-{val_accuracy:.2f}.h5\"\n",
    "#save_dir = os.path.join(os.getcwd(), './Ravdess_model/NoDA')\n",
    "#model_name = 'Ravdess_model_1_1.h5'\n",
    "\n",
    "#checkpoint = ModelCheckpoint(os.path.join(save_dir, filepath), monitor='val_accuracy',verbose=1, \n",
    "#                            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1503 samples, validate on 741 samples\n",
      "Epoch 1/200\n",
      "1503/1503 [==============================] - 4s 3ms/step - loss: 2.0917 - accuracy: 0.1437 - val_loss: 2.0799 - val_accuracy: 0.0783\n",
      "Epoch 2/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 2.0192 - accuracy: 0.1870 - val_loss: 2.0716 - val_accuracy: 0.1053\n",
      "Epoch 3/200\n",
      "1503/1503 [==============================] - 1s 432us/step - loss: 1.9639 - accuracy: 0.2595 - val_loss: 2.0542 - val_accuracy: 0.1255\n",
      "Epoch 4/200\n",
      "1503/1503 [==============================] - 1s 442us/step - loss: 1.9107 - accuracy: 0.2854 - val_loss: 2.0213 - val_accuracy: 0.1741\n",
      "Epoch 5/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 1.8709 - accuracy: 0.3067 - val_loss: 1.9735 - val_accuracy: 0.2551\n",
      "Epoch 6/200\n",
      "1503/1503 [==============================] - 1s 441us/step - loss: 1.8304 - accuracy: 0.3253 - val_loss: 1.9163 - val_accuracy: 0.2969\n",
      "Epoch 7/200\n",
      "1503/1503 [==============================] - 1s 444us/step - loss: 1.7982 - accuracy: 0.3533 - val_loss: 1.8603 - val_accuracy: 0.3414\n",
      "Epoch 8/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 1.7740 - accuracy: 0.3393 - val_loss: 1.8062 - val_accuracy: 0.3927\n",
      "Epoch 9/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.7458 - accuracy: 0.3699 - val_loss: 1.7612 - val_accuracy: 0.3981\n",
      "Epoch 10/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.7259 - accuracy: 0.3706 - val_loss: 1.7250 - val_accuracy: 0.4035\n",
      "Epoch 11/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.7040 - accuracy: 0.3906 - val_loss: 1.6973 - val_accuracy: 0.4076\n",
      "Epoch 12/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.6880 - accuracy: 0.3979 - val_loss: 1.6667 - val_accuracy: 0.4291\n",
      "Epoch 13/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.6642 - accuracy: 0.4158 - val_loss: 1.6430 - val_accuracy: 0.4332\n",
      "Epoch 14/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.6421 - accuracy: 0.4291 - val_loss: 1.6249 - val_accuracy: 0.4561\n",
      "Epoch 15/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.6267 - accuracy: 0.4398 - val_loss: 1.6008 - val_accuracy: 0.4480\n",
      "Epoch 16/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.6060 - accuracy: 0.4617 - val_loss: 1.5835 - val_accuracy: 0.4710\n",
      "Epoch 17/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 1.5994 - accuracy: 0.4617 - val_loss: 1.5718 - val_accuracy: 0.4804\n",
      "Epoch 18/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.5820 - accuracy: 0.4717 - val_loss: 1.5489 - val_accuracy: 0.4993\n",
      "Epoch 19/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.5602 - accuracy: 0.4804 - val_loss: 1.5388 - val_accuracy: 0.4926\n",
      "Epoch 20/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 1.5471 - accuracy: 0.5037 - val_loss: 1.5251 - val_accuracy: 0.4899\n",
      "Epoch 21/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.5280 - accuracy: 0.5017 - val_loss: 1.5121 - val_accuracy: 0.5020\n",
      "Epoch 22/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.5146 - accuracy: 0.5083 - val_loss: 1.4990 - val_accuracy: 0.4899\n",
      "Epoch 23/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 1.5005 - accuracy: 0.5150 - val_loss: 1.4818 - val_accuracy: 0.5169\n",
      "Epoch 24/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 1.4852 - accuracy: 0.5150 - val_loss: 1.4749 - val_accuracy: 0.5034\n",
      "Epoch 25/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.4758 - accuracy: 0.5276 - val_loss: 1.4531 - val_accuracy: 0.5209\n",
      "Epoch 26/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 1.4609 - accuracy: 0.5263 - val_loss: 1.4403 - val_accuracy: 0.5317\n",
      "Epoch 27/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.4523 - accuracy: 0.5403 - val_loss: 1.4369 - val_accuracy: 0.5344\n",
      "Epoch 28/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.4402 - accuracy: 0.5482 - val_loss: 1.4157 - val_accuracy: 0.5479\n",
      "Epoch 29/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.4200 - accuracy: 0.5509 - val_loss: 1.4099 - val_accuracy: 0.5358\n",
      "Epoch 30/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.4113 - accuracy: 0.5542 - val_loss: 1.4004 - val_accuracy: 0.5425\n",
      "Epoch 31/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.3890 - accuracy: 0.5755 - val_loss: 1.3866 - val_accuracy: 0.5196\n",
      "Epoch 32/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.3786 - accuracy: 0.5828 - val_loss: 1.3899 - val_accuracy: 0.5398\n",
      "Epoch 33/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 1.3587 - accuracy: 0.5975 - val_loss: 1.3596 - val_accuracy: 0.5574\n",
      "Epoch 34/200\n",
      "1503/1503 [==============================] - 1s 442us/step - loss: 1.3498 - accuracy: 0.5968 - val_loss: 1.3743 - val_accuracy: 0.5493\n",
      "Epoch 35/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.3438 - accuracy: 0.5908 - val_loss: 1.3309 - val_accuracy: 0.5762\n",
      "Epoch 36/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 1.3212 - accuracy: 0.6061 - val_loss: 1.3189 - val_accuracy: 0.5789\n",
      "Epoch 37/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.3118 - accuracy: 0.6121 - val_loss: 1.3080 - val_accuracy: 0.5884\n",
      "Epoch 38/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.2939 - accuracy: 0.6141 - val_loss: 1.3012 - val_accuracy: 0.5924\n",
      "Epoch 39/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.2765 - accuracy: 0.6301 - val_loss: 1.3017 - val_accuracy: 0.5897\n",
      "Epoch 40/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.2729 - accuracy: 0.6261 - val_loss: 1.2764 - val_accuracy: 0.5870\n",
      "Epoch 41/200\n",
      "1503/1503 [==============================] - 1s 444us/step - loss: 1.2568 - accuracy: 0.6334 - val_loss: 1.2847 - val_accuracy: 0.5857\n",
      "Epoch 42/200\n",
      "1503/1503 [==============================] - 1s 441us/step - loss: 1.2542 - accuracy: 0.6314 - val_loss: 1.2673 - val_accuracy: 0.6005\n",
      "Epoch 43/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 1.2286 - accuracy: 0.6434 - val_loss: 1.2330 - val_accuracy: 0.6019\n",
      "Epoch 44/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 1.2161 - accuracy: 0.6660 - val_loss: 1.2315 - val_accuracy: 0.6059\n",
      "Epoch 45/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 1.2042 - accuracy: 0.6567 - val_loss: 1.2267 - val_accuracy: 0.6221\n",
      "Epoch 46/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 1.1928 - accuracy: 0.6607 - val_loss: 1.2253 - val_accuracy: 0.6235\n",
      "Epoch 47/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.1861 - accuracy: 0.6707 - val_loss: 1.2081 - val_accuracy: 0.6316\n",
      "Epoch 48/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.1750 - accuracy: 0.6660 - val_loss: 1.1943 - val_accuracy: 0.6343\n",
      "Epoch 49/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 1.1563 - accuracy: 0.6813 - val_loss: 1.1938 - val_accuracy: 0.6140\n",
      "Epoch 50/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.1467 - accuracy: 0.6773 - val_loss: 1.1706 - val_accuracy: 0.6370\n",
      "Epoch 51/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 1.1365 - accuracy: 0.6846 - val_loss: 1.1942 - val_accuracy: 0.6140\n",
      "Epoch 52/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 1.1313 - accuracy: 0.6880 - val_loss: 1.1582 - val_accuracy: 0.6370\n",
      "Epoch 53/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.1201 - accuracy: 0.6913 - val_loss: 1.1481 - val_accuracy: 0.6491\n",
      "Epoch 54/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.0955 - accuracy: 0.7046 - val_loss: 1.1454 - val_accuracy: 0.6491\n",
      "Epoch 55/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.0934 - accuracy: 0.6979 - val_loss: 1.1471 - val_accuracy: 0.6559\n",
      "Epoch 56/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 1.0923 - accuracy: 0.7019 - val_loss: 1.1331 - val_accuracy: 0.6653\n",
      "Epoch 57/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.0727 - accuracy: 0.7059 - val_loss: 1.1379 - val_accuracy: 0.6707\n",
      "Epoch 58/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 1.0739 - accuracy: 0.7179 - val_loss: 1.1077 - val_accuracy: 0.6505\n",
      "Epoch 59/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 1.0550 - accuracy: 0.7186 - val_loss: 1.1162 - val_accuracy: 0.6532\n",
      "Epoch 60/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 1.0535 - accuracy: 0.7226 - val_loss: 1.0962 - val_accuracy: 0.6640\n",
      "Epoch 61/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 1.0369 - accuracy: 0.7299 - val_loss: 1.1037 - val_accuracy: 0.6680\n",
      "Epoch 62/200\n",
      "1503/1503 [==============================] - 1s 443us/step - loss: 1.0200 - accuracy: 0.7345 - val_loss: 1.0905 - val_accuracy: 0.6707\n",
      "Epoch 63/200\n",
      "1503/1503 [==============================] - 1s 442us/step - loss: 1.0177 - accuracy: 0.7345 - val_loss: 1.0945 - val_accuracy: 0.6640\n",
      "Epoch 64/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 1.0092 - accuracy: 0.7452 - val_loss: 1.0701 - val_accuracy: 0.6815\n",
      "Epoch 65/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 1.0148 - accuracy: 0.7259 - val_loss: 1.0738 - val_accuracy: 0.6694\n",
      "Epoch 66/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.9949 - accuracy: 0.7418 - val_loss: 1.0752 - val_accuracy: 0.6788\n",
      "Epoch 67/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 0.9873 - accuracy: 0.7492 - val_loss: 1.0628 - val_accuracy: 0.6721\n",
      "Epoch 68/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.9699 - accuracy: 0.7518 - val_loss: 1.0631 - val_accuracy: 0.6802\n",
      "Epoch 69/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 0.9678 - accuracy: 0.7478 - val_loss: 1.0507 - val_accuracy: 0.6734\n",
      "Epoch 70/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.9622 - accuracy: 0.7598 - val_loss: 1.0672 - val_accuracy: 0.6653\n",
      "Epoch 71/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.9583 - accuracy: 0.7591 - val_loss: 1.0471 - val_accuracy: 0.6869\n",
      "Epoch 72/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.9462 - accuracy: 0.7591 - val_loss: 1.0426 - val_accuracy: 0.6761\n",
      "Epoch 73/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 0.9500 - accuracy: 0.7578 - val_loss: 1.0527 - val_accuracy: 0.6815\n",
      "Epoch 74/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.9318 - accuracy: 0.7658 - val_loss: 1.0349 - val_accuracy: 0.6856\n",
      "Epoch 75/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.9317 - accuracy: 0.7645 - val_loss: 1.0331 - val_accuracy: 0.6721\n",
      "Epoch 76/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.9198 - accuracy: 0.7791 - val_loss: 1.0318 - val_accuracy: 0.6761\n",
      "Epoch 77/200\n",
      "1503/1503 [==============================] - 1s 441us/step - loss: 0.9073 - accuracy: 0.7758 - val_loss: 1.0472 - val_accuracy: 0.6667\n",
      "Epoch 78/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.9022 - accuracy: 0.7811 - val_loss: 1.0117 - val_accuracy: 0.6842\n",
      "Epoch 79/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.8987 - accuracy: 0.7771 - val_loss: 1.0156 - val_accuracy: 0.6937\n",
      "Epoch 80/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.9017 - accuracy: 0.7804 - val_loss: 1.0212 - val_accuracy: 0.6829\n",
      "Epoch 81/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.8878 - accuracy: 0.7705 - val_loss: 1.0037 - val_accuracy: 0.6896\n",
      "Epoch 82/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.8712 - accuracy: 0.7884 - val_loss: 1.0114 - val_accuracy: 0.6802\n",
      "Epoch 83/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.8766 - accuracy: 0.7904 - val_loss: 0.9914 - val_accuracy: 0.6896\n",
      "Epoch 84/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.8652 - accuracy: 0.7977 - val_loss: 1.0060 - val_accuracy: 0.6775\n",
      "Epoch 85/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 0.8539 - accuracy: 0.7898 - val_loss: 0.9959 - val_accuracy: 0.6883\n",
      "Epoch 86/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.8486 - accuracy: 0.7964 - val_loss: 0.9835 - val_accuracy: 0.7031\n",
      "Epoch 87/200\n",
      "1503/1503 [==============================] - 1s 443us/step - loss: 0.8408 - accuracy: 0.7944 - val_loss: 0.9964 - val_accuracy: 0.7058\n",
      "Epoch 88/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.8391 - accuracy: 0.7931 - val_loss: 0.9685 - val_accuracy: 0.7018\n",
      "Epoch 89/200\n",
      "1503/1503 [==============================] - 1s 441us/step - loss: 0.8308 - accuracy: 0.8004 - val_loss: 0.9942 - val_accuracy: 0.6964\n",
      "Epoch 90/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.8287 - accuracy: 0.8011 - val_loss: 0.9660 - val_accuracy: 0.7085\n",
      "Epoch 91/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.8214 - accuracy: 0.8150 - val_loss: 0.9548 - val_accuracy: 0.7072\n",
      "Epoch 92/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.8038 - accuracy: 0.8204 - val_loss: 0.9707 - val_accuracy: 0.6964\n",
      "Epoch 93/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.8053 - accuracy: 0.8110 - val_loss: 0.9654 - val_accuracy: 0.6883\n",
      "Epoch 94/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.8125 - accuracy: 0.8104 - val_loss: 0.9706 - val_accuracy: 0.6964\n",
      "Epoch 95/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.7952 - accuracy: 0.8177 - val_loss: 0.9539 - val_accuracy: 0.6964\n",
      "Epoch 96/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.7920 - accuracy: 0.8144 - val_loss: 0.9520 - val_accuracy: 0.7085\n",
      "Epoch 97/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.7848 - accuracy: 0.8263 - val_loss: 0.9763 - val_accuracy: 0.6802\n",
      "Epoch 98/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.7839 - accuracy: 0.8150 - val_loss: 0.9637 - val_accuracy: 0.6869\n",
      "Epoch 99/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.7758 - accuracy: 0.8190 - val_loss: 0.9554 - val_accuracy: 0.7018\n",
      "Epoch 100/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.7693 - accuracy: 0.8277 - val_loss: 0.9813 - val_accuracy: 0.6694\n",
      "Epoch 101/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.7679 - accuracy: 0.8330 - val_loss: 0.9308 - val_accuracy: 0.7220\n",
      "Epoch 102/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.7543 - accuracy: 0.8310 - val_loss: 0.9406 - val_accuracy: 0.7112\n",
      "Epoch 103/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.7539 - accuracy: 0.8317 - val_loss: 0.9368 - val_accuracy: 0.7099\n",
      "Epoch 104/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.7472 - accuracy: 0.8330 - val_loss: 0.9258 - val_accuracy: 0.7112\n",
      "Epoch 105/200\n",
      "1503/1503 [==============================] - 1s 441us/step - loss: 0.7459 - accuracy: 0.8370 - val_loss: 0.9231 - val_accuracy: 0.7099\n",
      "Epoch 106/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.7429 - accuracy: 0.8310 - val_loss: 0.9291 - val_accuracy: 0.7166\n",
      "Epoch 107/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.7362 - accuracy: 0.8410 - val_loss: 0.9388 - val_accuracy: 0.6991\n",
      "Epoch 108/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.7249 - accuracy: 0.8377 - val_loss: 0.9581 - val_accuracy: 0.6788\n",
      "Epoch 109/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.7155 - accuracy: 0.8483 - val_loss: 0.9057 - val_accuracy: 0.7152\n",
      "Epoch 110/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.7143 - accuracy: 0.8383 - val_loss: 0.9205 - val_accuracy: 0.7126\n",
      "Epoch 111/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.7071 - accuracy: 0.8503 - val_loss: 0.9241 - val_accuracy: 0.7126\n",
      "Epoch 112/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 0.7074 - accuracy: 0.8456 - val_loss: 0.9053 - val_accuracy: 0.7193\n",
      "Epoch 113/200\n",
      "1503/1503 [==============================] - 1s 446us/step - loss: 0.7023 - accuracy: 0.8530 - val_loss: 0.9217 - val_accuracy: 0.7126\n",
      "Epoch 114/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 0.6934 - accuracy: 0.8490 - val_loss: 0.9132 - val_accuracy: 0.7206\n",
      "Epoch 115/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.6899 - accuracy: 0.8589 - val_loss: 0.9317 - val_accuracy: 0.7004\n",
      "Epoch 116/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 0.6819 - accuracy: 0.8476 - val_loss: 0.8988 - val_accuracy: 0.7274\n",
      "Epoch 117/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.6781 - accuracy: 0.8589 - val_loss: 0.9052 - val_accuracy: 0.7152\n",
      "Epoch 118/200\n",
      "1503/1503 [==============================] - 1s 444us/step - loss: 0.6881 - accuracy: 0.8490 - val_loss: 0.9138 - val_accuracy: 0.7031\n",
      "Epoch 119/200\n",
      "1503/1503 [==============================] - 1s 445us/step - loss: 0.6744 - accuracy: 0.8589 - val_loss: 0.8998 - val_accuracy: 0.7287\n",
      "Epoch 120/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.6715 - accuracy: 0.8616 - val_loss: 0.8893 - val_accuracy: 0.7220\n",
      "Epoch 121/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.6609 - accuracy: 0.8623 - val_loss: 0.9006 - val_accuracy: 0.7206\n",
      "Epoch 122/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.6493 - accuracy: 0.8736 - val_loss: 0.8977 - val_accuracy: 0.7179\n",
      "Epoch 123/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.6477 - accuracy: 0.8656 - val_loss: 0.9136 - val_accuracy: 0.7045\n",
      "Epoch 124/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.6521 - accuracy: 0.8623 - val_loss: 0.8789 - val_accuracy: 0.7382\n",
      "Epoch 125/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.6444 - accuracy: 0.8729 - val_loss: 0.8757 - val_accuracy: 0.7314\n",
      "Epoch 126/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.6392 - accuracy: 0.8696 - val_loss: 0.8860 - val_accuracy: 0.7287\n",
      "Epoch 127/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.6488 - accuracy: 0.8656 - val_loss: 0.8875 - val_accuracy: 0.7193\n",
      "Epoch 128/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.6270 - accuracy: 0.8689 - val_loss: 0.9122 - val_accuracy: 0.7126\n",
      "Epoch 129/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.6226 - accuracy: 0.8789 - val_loss: 0.8988 - val_accuracy: 0.7072\n",
      "Epoch 130/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.6177 - accuracy: 0.8816 - val_loss: 0.8590 - val_accuracy: 0.7341\n",
      "Epoch 131/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.6158 - accuracy: 0.8782 - val_loss: 0.8663 - val_accuracy: 0.7341\n",
      "Epoch 132/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.6087 - accuracy: 0.8876 - val_loss: 0.8710 - val_accuracy: 0.7328\n",
      "Epoch 133/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.6135 - accuracy: 0.8736 - val_loss: 0.8639 - val_accuracy: 0.7193\n",
      "Epoch 134/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.6007 - accuracy: 0.8902 - val_loss: 0.8529 - val_accuracy: 0.7341\n",
      "Epoch 135/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.5995 - accuracy: 0.8849 - val_loss: 0.8985 - val_accuracy: 0.7045\n",
      "Epoch 136/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.6003 - accuracy: 0.8809 - val_loss: 0.8565 - val_accuracy: 0.7422\n",
      "Epoch 137/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.5841 - accuracy: 0.8922 - val_loss: 0.8579 - val_accuracy: 0.7287\n",
      "Epoch 138/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.5824 - accuracy: 0.9022 - val_loss: 0.8565 - val_accuracy: 0.7206\n",
      "Epoch 139/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.5874 - accuracy: 0.8876 - val_loss: 0.8700 - val_accuracy: 0.7193\n",
      "Epoch 140/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.5852 - accuracy: 0.8876 - val_loss: 0.8375 - val_accuracy: 0.7490\n",
      "Epoch 141/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.5792 - accuracy: 0.8982 - val_loss: 0.8594 - val_accuracy: 0.7341\n",
      "Epoch 142/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.5741 - accuracy: 0.8935 - val_loss: 0.8505 - val_accuracy: 0.7368\n",
      "Epoch 143/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.5631 - accuracy: 0.9035 - val_loss: 0.8567 - val_accuracy: 0.7341\n",
      "Epoch 144/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.5535 - accuracy: 0.8962 - val_loss: 0.8566 - val_accuracy: 0.7220\n",
      "Epoch 145/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.5550 - accuracy: 0.9029 - val_loss: 0.8533 - val_accuracy: 0.7206\n",
      "Epoch 146/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.5535 - accuracy: 0.9002 - val_loss: 0.8404 - val_accuracy: 0.7368\n",
      "Epoch 147/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.5391 - accuracy: 0.8975 - val_loss: 0.8318 - val_accuracy: 0.7382\n",
      "Epoch 148/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.5453 - accuracy: 0.9082 - val_loss: 0.8376 - val_accuracy: 0.7355\n",
      "Epoch 149/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.5352 - accuracy: 0.9095 - val_loss: 0.8439 - val_accuracy: 0.7328\n",
      "Epoch 150/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.5405 - accuracy: 0.9062 - val_loss: 0.8405 - val_accuracy: 0.7368\n",
      "Epoch 151/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.5469 - accuracy: 0.9069 - val_loss: 0.8486 - val_accuracy: 0.7301\n",
      "Epoch 152/200\n",
      "1503/1503 [==============================] - 1s 442us/step - loss: 0.5308 - accuracy: 0.9135 - val_loss: 0.8250 - val_accuracy: 0.7395\n",
      "Epoch 153/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.5107 - accuracy: 0.9235 - val_loss: 0.8480 - val_accuracy: 0.7314\n",
      "Epoch 154/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.5189 - accuracy: 0.9168 - val_loss: 0.8347 - val_accuracy: 0.7301\n",
      "Epoch 155/200\n",
      "1503/1503 [==============================] - 1s 445us/step - loss: 0.5137 - accuracy: 0.9148 - val_loss: 0.8408 - val_accuracy: 0.7355\n",
      "Epoch 156/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.5124 - accuracy: 0.9095 - val_loss: 0.8314 - val_accuracy: 0.7301\n",
      "Epoch 157/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.5029 - accuracy: 0.9182 - val_loss: 0.8340 - val_accuracy: 0.7368\n",
      "Epoch 158/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.5069 - accuracy: 0.9275 - val_loss: 0.8236 - val_accuracy: 0.7463\n",
      "Epoch 159/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.5136 - accuracy: 0.9128 - val_loss: 0.8346 - val_accuracy: 0.7193\n",
      "Epoch 160/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.5036 - accuracy: 0.9182 - val_loss: 0.8121 - val_accuracy: 0.7449\n",
      "Epoch 161/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.4778 - accuracy: 0.9281 - val_loss: 0.8203 - val_accuracy: 0.7476\n",
      "Epoch 162/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.4983 - accuracy: 0.9255 - val_loss: 0.8320 - val_accuracy: 0.7341\n",
      "Epoch 163/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.4843 - accuracy: 0.9288 - val_loss: 0.8224 - val_accuracy: 0.7503\n",
      "Epoch 164/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.4916 - accuracy: 0.9235 - val_loss: 0.8255 - val_accuracy: 0.7382\n",
      "Epoch 165/200\n",
      "1503/1503 [==============================] - 1s 434us/step - loss: 0.4703 - accuracy: 0.9381 - val_loss: 0.8102 - val_accuracy: 0.7463\n",
      "Epoch 166/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.4746 - accuracy: 0.9281 - val_loss: 0.8470 - val_accuracy: 0.7260\n",
      "Epoch 167/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.4764 - accuracy: 0.9275 - val_loss: 0.8329 - val_accuracy: 0.7301\n",
      "Epoch 168/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.4704 - accuracy: 0.9295 - val_loss: 0.8070 - val_accuracy: 0.7368\n",
      "Epoch 169/200\n",
      "1503/1503 [==============================] - 1s 439us/step - loss: 0.4652 - accuracy: 0.9308 - val_loss: 0.8273 - val_accuracy: 0.7368\n",
      "Epoch 170/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.4579 - accuracy: 0.9275 - val_loss: 0.8156 - val_accuracy: 0.7449\n",
      "Epoch 171/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.4539 - accuracy: 0.9315 - val_loss: 0.8151 - val_accuracy: 0.7463\n",
      "Epoch 172/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.4514 - accuracy: 0.9341 - val_loss: 0.8143 - val_accuracy: 0.7530\n",
      "Epoch 173/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.4501 - accuracy: 0.9421 - val_loss: 0.7981 - val_accuracy: 0.7517\n",
      "Epoch 174/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.4588 - accuracy: 0.9328 - val_loss: 0.7986 - val_accuracy: 0.7517\n",
      "Epoch 175/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.4445 - accuracy: 0.9341 - val_loss: 0.8116 - val_accuracy: 0.7395\n",
      "Epoch 176/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.4331 - accuracy: 0.9514 - val_loss: 0.8112 - val_accuracy: 0.7476\n",
      "Epoch 177/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.4367 - accuracy: 0.9395 - val_loss: 0.7975 - val_accuracy: 0.7503\n",
      "Epoch 178/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.4373 - accuracy: 0.9461 - val_loss: 0.8009 - val_accuracy: 0.7517\n",
      "Epoch 179/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.4314 - accuracy: 0.9395 - val_loss: 0.8192 - val_accuracy: 0.7314\n",
      "Epoch 180/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.4245 - accuracy: 0.9448 - val_loss: 0.7913 - val_accuracy: 0.7611\n",
      "Epoch 181/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.4217 - accuracy: 0.9474 - val_loss: 0.8027 - val_accuracy: 0.7314\n",
      "Epoch 182/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.4111 - accuracy: 0.9508 - val_loss: 0.8175 - val_accuracy: 0.7463\n",
      "Epoch 183/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.4185 - accuracy: 0.9468 - val_loss: 0.7992 - val_accuracy: 0.7503\n",
      "Epoch 184/200\n",
      "1503/1503 [==============================] - 1s 441us/step - loss: 0.4196 - accuracy: 0.9468 - val_loss: 0.7820 - val_accuracy: 0.7571\n",
      "Epoch 185/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.4189 - accuracy: 0.9428 - val_loss: 0.7941 - val_accuracy: 0.7463\n",
      "Epoch 186/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.4065 - accuracy: 0.9454 - val_loss: 0.8146 - val_accuracy: 0.7314\n",
      "Epoch 187/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.3964 - accuracy: 0.9574 - val_loss: 0.7937 - val_accuracy: 0.7571\n",
      "Epoch 188/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.4120 - accuracy: 0.9514 - val_loss: 0.7861 - val_accuracy: 0.7557\n",
      "Epoch 189/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.3978 - accuracy: 0.9541 - val_loss: 0.7712 - val_accuracy: 0.7625\n",
      "Epoch 190/200\n",
      "1503/1503 [==============================] - 1s 442us/step - loss: 0.3904 - accuracy: 0.9554 - val_loss: 0.7800 - val_accuracy: 0.7517\n",
      "Epoch 191/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.3975 - accuracy: 0.9554 - val_loss: 0.8409 - val_accuracy: 0.7139\n",
      "Epoch 192/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.3986 - accuracy: 0.9568 - val_loss: 0.8168 - val_accuracy: 0.7355\n",
      "Epoch 193/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.3869 - accuracy: 0.9601 - val_loss: 0.7843 - val_accuracy: 0.7503\n",
      "Epoch 194/200\n",
      "1503/1503 [==============================] - 1s 433us/step - loss: 0.3823 - accuracy: 0.9594 - val_loss: 0.7860 - val_accuracy: 0.7611\n",
      "Epoch 195/200\n",
      "1503/1503 [==============================] - 1s 440us/step - loss: 0.3893 - accuracy: 0.9554 - val_loss: 0.8084 - val_accuracy: 0.7328\n",
      "Epoch 196/200\n",
      "1503/1503 [==============================] - 1s 438us/step - loss: 0.3771 - accuracy: 0.9581 - val_loss: 0.7694 - val_accuracy: 0.7571\n",
      "Epoch 197/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.3604 - accuracy: 0.9634 - val_loss: 0.7766 - val_accuracy: 0.7665\n",
      "Epoch 198/200\n",
      "1503/1503 [==============================] - 1s 436us/step - loss: 0.3724 - accuracy: 0.9541 - val_loss: 0.7935 - val_accuracy: 0.7287\n",
      "Epoch 199/200\n",
      "1503/1503 [==============================] - 1s 435us/step - loss: 0.3716 - accuracy: 0.9614 - val_loss: 0.7651 - val_accuracy: 0.7638\n",
      "Epoch 200/200\n",
      "1503/1503 [==============================] - 1s 437us/step - loss: 0.3724 - accuracy: 0.9647 - val_loss: 0.7721 - val_accuracy: 0.7571\n"
     ]
    }
   ],
   "source": [
    "cnnhistory=model.fit(x_traincnn, \n",
    "                     y_train, \n",
    "                     batch_size=32, \n",
    "                     epochs=200, \n",
    "                     validation_data=(x_testcnn, y_test))\n",
    "                     \n",
    "                     \n",
    "                     #callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dyn_noise_trim\n",
    "plt.plot(cnnhistory.history['loss'])\n",
    "plt.plot(cnnhistory.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dyn_noise_trim\n",
    "plt.plot(cnnhistory.history['accuracy'])\n",
    "plt.plot(cnnhistory.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_testcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Ytest = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = classification_report(new_Ytest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.69      0.72        55\n",
      "           1       0.79      0.90      0.84       119\n",
      "           2       0.85      0.68      0.75       113\n",
      "           3       0.76      0.71      0.74        98\n",
      "           4       0.78      0.88      0.83       119\n",
      "           5       0.74      0.69      0.72       121\n",
      "           6       0.59      0.59      0.59        58\n",
      "           7       0.69      0.79      0.74        58\n",
      "\n",
      "    accuracy                           0.76       741\n",
      "   macro avg       0.74      0.74      0.74       741\n",
      "weighted avg       0.76      0.76      0.76       741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 38   7   1   1   0   2   3   3]\n",
      " [  5 107   2   2   0   2   1   0]\n",
      " [  1   7  77   2   9   8   3   6]\n",
      " [  2   7   2  70   2   7   7   1]\n",
      " [  2   2   0   0 105   3   4   3]\n",
      " [  0   0   6  14   7  84   4   6]\n",
      " [  1   6   0   3   8   4  34   2]\n",
      " [  1   0   3   0   3   3   2  46]]\n"
     ]
    }
   ],
   "source": [
    "matrix = confusion_matrix(new_Ytest, predictions)\n",
    "print (matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'Adam_Enhance_trim_only_epooch_200.h5'\n",
    "#save_dir = 'Ravdess_model'\n",
    "# Save model and weights\n",
    "#if not os.path.isdir(save_dir):\n",
    "#    os.makedirs(save_dir)\n",
    "#model_path = os.path.join(save_dir, model_name)\n",
    "model.save('Adam_Enhance_trim_only_epooch_200.h5')\n",
    "#print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, None, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8)                 0         \n",
      "=================================================================\n",
      "Total params: 497,672\n",
      "Trainable params: 495,880\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loaded_model = keras.models.load_model('Adam_Enhance_trim_only_epooch_200.h5')\n",
    "loaded_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741/741 [==============================] - 0s 399us/step\n",
      "Restored model, accuracy: 75.71%\n"
     ]
    }
   ],
   "source": [
    "#loss, acc = loaded_model.evaluate(x_testcnn, y_test)\n",
    "loss, acc = loaded_model.evaluate(x_testcnn, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the Voice actor 23 and 24 (trim)\n",
    "path2 = '/home/jovyan/at083-group21/dataset/final_test_datasaet_model1/'\n",
    "\n",
    "lst2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Start load Data. Start time: 1585285755.0022807 ---\n",
      "--- Data loaded. Loading time: 13.348771810531616 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#trim\n",
    "## Trim\n",
    "\n",
    "start_time = time.time()\n",
    "print(\"--- Start load Data. Start time: %s ---\" % (start_time))\n",
    "for subdir, dirs, files in os.walk(path2):\n",
    "\n",
    "    for file in files:\n",
    "        try:\n",
    "            #Load librosa array, obtain mfcss, store the file and the mcss information in a new array\n",
    "            X, sample_rate = librosa.load(os.path.join(subdir,file), res_type='kaiser_fast')\n",
    "            \n",
    "            #####Data Augmentation\n",
    "                        \n",
    "            X = trim(X)\n",
    "            sample_rate = np.array(sample_rate)\n",
    "\n",
    "            \n",
    "            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=100).T,axis=0) \n",
    "            # The instruction below converts the labels (from 1 to 8) to a series from 0 to 7\n",
    "            # This is because our predictor needs to start from 0 otherwise it will try to predict also 0.\n",
    "            file = int(file[7:8]) - 1 \n",
    "            arr = mfccs, file\n",
    "            lst2.append(arr)\n",
    "          # If the file is not valid, skip it\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "print(\"--- Data loaded. Loading time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and y: zip makes a list of all the first elements, and a list of all the second elements.\n",
    "X, y = zip(*lst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((208, 100), (208,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a quick test\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207, 100, 1), (1, 100, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincnn2 = np.expand_dims(X_train2, axis=2)\n",
    "x_testcnn2 = np.expand_dims(X_test2, axis=2)\n",
    "\n",
    "x_traincnn2.shape, x_testcnn2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = loaded_model.predict_classes(x_traincnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Ytest2 = y_train2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(new_Ytest2, predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.47      0.64        15\n",
      "           1       0.65      0.94      0.77        32\n",
      "           2       0.64      0.22      0.33        32\n",
      "           3       0.75      0.75      0.75        32\n",
      "           4       0.61      0.34      0.44        32\n",
      "           5       0.50      0.84      0.63        32\n",
      "           6       0.40      0.50      0.44        16\n",
      "           7       0.58      0.69      0.63        16\n",
      "\n",
      "    accuracy                           0.60       207\n",
      "   macro avg       0.64      0.59      0.58       207\n",
      "weighted avg       0.64      0.60      0.58       207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7  3  0  1  1  1  2  0]\n",
      " [ 0 30  0  1  0  0  1  0]\n",
      " [ 0  7  7  1  0  9  4  4]\n",
      " [ 0  5  0 24  0  1  1  1]\n",
      " [ 0  0  1  3 11 12  2  3]\n",
      " [ 0  0  2  2  1 27  0  0]\n",
      " [ 0  1  0  0  3  4  8  0]\n",
      " [ 0  0  1  0  2  0  2 11]]\n"
     ]
    }
   ],
   "source": [
    "matrix2 = confusion_matrix(new_Ytest2, predictions2)\n",
    "print (matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/207 [==============================] - 0s 105us/step\n",
      "Restored model, accuracy: 60.39%\n"
     ]
    }
   ],
   "source": [
    "#loss, acc = loaded_model.evaluate(x_testcnn, y_test)\n",
    "loss2, acc2 = loaded_model.evaluate(x_traincnn2, y_train2)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
